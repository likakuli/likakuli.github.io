<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>问题排查 - 分类 - kaku&#39;s blog</title>
        <link>https://www.likakuli.com/categories/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</link>
        <description>问题排查 - 分类 - kaku&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>1154584512@qq.com (kaku)</managingEditor>
            <webMaster>1154584512@qq.com (kaku)</webMaster><lastBuildDate>Thu, 24 Dec 2020 17:26:12 &#43;0800</lastBuildDate><atom:link href="https://www.likakuli.com/categories/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/" rel="self" type="application/rss+xml" /><item>
    <title>Dockerd资源泄露系列 - 3</title>
    <link>https://www.likakuli.com/posts/docker-leak3/</link>
    <pubDate>Thu, 24 Dec 2020 17:26:12 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/docker-leak3/</guid>
    <description><![CDATA[现象 线上k8s集群报警，宿主fd利用率超过80%，登陆查看dockerd内存使用26G 排查思路 由于之前已经遇到过多次dockerd资源泄露的]]></description>
</item><item>
    <title>Pod terminating2</title>
    <link>https://www.likakuli.com/posts/docker-pod-terminating2/</link>
    <pubDate>Sat, 31 Oct 2020 10:51:39 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/docker-pod-terminating2/</guid>
    <description><![CDATA[1. 背景 承接上文，近期我们排查弹性云线上几起故障时，故障由多个因素共同引起，列举如下： 弹性云在逐步灰度升级docker版本至 18.06.3-ce 由于历史原因，弹]]></description>
</item><item>
    <title>Pod terminating</title>
    <link>https://www.likakuli.com/posts/docker-pod-terminating/</link>
    <pubDate>Sat, 31 Oct 2020 10:37:37 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/docker-pod-terminating/</guid>
    <description><![CDATA[转载自组内同事stupig 1. 背景 近期，弹性云线上集群发生了几起特殊的容器漂移失败事件，其特殊之处在于容器处于Pod Terminating状态]]></description>
</item><item>
    <title>docker hang问题排查</title>
    <link>https://www.likakuli.com/posts/docker-hang/</link>
    <pubDate>Mon, 26 Oct 2020 21:52:54 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/docker-hang/</guid>
    <description><![CDATA[转载自组内同事 1. 背景 最近升级了一版kubelet，修复因kubelet删除Pod慢导致平台删除集群超时的问题。在灰度redis隔离集群的时候]]></description>
</item><item>
    <title>netns泄露</title>
    <link>https://www.likakuli.com/posts/netns-leak/</link>
    <pubDate>Mon, 26 Oct 2020 21:42:48 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/netns-leak/</guid>
    <description><![CDATA[1. 揭开面纱 周一，接到RD反馈线上容器网络访问存在异常，具体线上描述如下： 上游服务driver-api所有容器访问下游服务duse-api某一]]></description>
</item><item>
    <title>Kubelet重启导致容器重启</title>
    <link>https://www.likakuli.com/posts/kubernetes-kubelet-restart/</link>
    <pubDate>Mon, 26 Oct 2020 21:27:30 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/kubernetes-kubelet-restart/</guid>
    <description><![CDATA[问题描述 在修复cgroup泄漏问题时会现停掉kubelet，待修复完成后启动kubelet组件，重启后收到业务反馈，业务容器重启了。 问题排查]]></description>
</item><item>
    <title>Knative健康检查</title>
    <link>https://www.likakuli.com/posts/knative-healthcheck/</link>
    <pubDate>Thu, 20 Aug 2020 13:26:19 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/knative-healthcheck/</guid>
    <description><![CDATA[背景 knative 0.14.0 实际修改可能与贴出来的代码不符，贴出来的代码只是为了方便快速实现功能 在支持了前面的定制功能后，集群中部署ksvc服务时会报Ingre]]></description>
</item><item>
    <title>Endpoint异常变化</title>
    <link>https://www.likakuli.com/posts/kubernetes-ep-event/</link>
    <pubDate>Tue, 23 Jun 2020 19:53:31 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/kubernetes-ep-event/</guid>
    <description><![CDATA[背景 k8s 1.12.4 包含自定义功能 线上集群在批量原地升级时出现流量异常问题，大体流程如下： 批量摘流，并等待7秒 批量删除容器 watch到Endpoint ready]]></description>
</item><item>
    <title>Sidecar优雅退出</title>
    <link>https://www.likakuli.com/posts/kubernetes-graceful-shutdown/</link>
    <pubDate>Tue, 23 Jun 2020 19:46:45 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/kubernetes-graceful-shutdown/</guid>
    <description><![CDATA[背景 codis集群在接入弹性云测试时发现容器漂移失败，通过集群日志看，提示 调度超时，去界面查看，已经调度成功了（调度成功的标志就是已经有宿主]]></description>
</item><item>
    <title>Kube-controller-manager同步数据慢</title>
    <link>https://www.likakuli.com/posts/kubernetes-controllerrevisionhistory-bug/</link>
    <pubDate>Wed, 01 Apr 2020 10:52:12 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/kubernetes-controllerrevisionhistory-bug/</guid>
    <description><![CDATA[背景 版本1.12.4 线上遇到kube-controller-manager重启慢的问题，具体表现为进程重启虽然速度快，但是重启完所有数据都同]]></description>
</item></channel>
</rss>

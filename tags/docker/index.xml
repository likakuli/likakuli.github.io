<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>docker - 标签 - kaku&#39;s blog</title>
        <link>https://www.likakuli.com/tags/docker/</link>
        <description>docker - 标签 - kaku&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>1154584512@qq.com (kaku)</managingEditor>
            <webMaster>1154584512@qq.com (kaku)</webMaster><lastBuildDate>Thu, 24 Dec 2020 17:26:12 &#43;0800</lastBuildDate><atom:link href="https://www.likakuli.com/tags/docker/" rel="self" type="application/rss+xml" /><item>
    <title>Dockerd资源泄露系列 - 3</title>
    <link>https://www.likakuli.com/posts/docker-leak3/</link>
    <pubDate>Thu, 24 Dec 2020 17:26:12 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/docker-leak3/</guid>
    <description><![CDATA[现象 线上k8s集群报警，宿主fd利用率超过80%，登陆查看dockerd内存使用26G 排查思路 由于之前已经遇到过多次dockerd资源泄露的]]></description>
</item><item>
    <title>Pod terminating2</title>
    <link>https://www.likakuli.com/posts/docker-pod-terminating2/</link>
    <pubDate>Sat, 31 Oct 2020 10:51:39 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/docker-pod-terminating2/</guid>
    <description><![CDATA[1. 背景 承接上文，近期我们排查弹性云线上几起故障时，故障由多个因素共同引起，列举如下： 弹性云在逐步灰度升级docker版本至 18.06.3-ce 由于历史原因，弹]]></description>
</item><item>
    <title>Pod terminating</title>
    <link>https://www.likakuli.com/posts/docker-pod-terminating/</link>
    <pubDate>Sat, 31 Oct 2020 10:37:37 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/docker-pod-terminating/</guid>
    <description><![CDATA[转载自组内同事stupig 1. 背景 近期，弹性云线上集群发生了几起特殊的容器漂移失败事件，其特殊之处在于容器处于Pod Terminating状态]]></description>
</item><item>
    <title>docker hang问题排查</title>
    <link>https://www.likakuli.com/posts/docker-hang/</link>
    <pubDate>Mon, 26 Oct 2020 21:52:54 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/docker-hang/</guid>
    <description><![CDATA[转载自组内同事 1. 背景 最近升级了一版kubelet，修复因kubelet删除Pod慢导致平台删除集群超时的问题。在灰度redis隔离集群的时候]]></description>
</item><item>
    <title>Dockerd内存泄露</title>
    <link>https://www.likakuli.com/posts/dockerd-memory-leak1/</link>
    <pubDate>Tue, 09 Jul 2019 20:06:53 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/dockerd-memory-leak1/</guid>
    <description><![CDATA[背景 线上部分宿主机dockerd占用内存过大，有的甚至超过100G，而整个宿主上的容器使用的内存还不如dockerd一个进程使用的多，现在的]]></description>
</item><item>
    <title>Dragonfly &#43; Harbor实现的p2p镜像分发</title>
    <link>https://www.likakuli.com/posts/dragonfly/</link>
    <pubDate>Thu, 13 Sep 2018 20:17:52 &#43;0800</pubDate>
    <author>作者</author>
    <guid>https://www.likakuli.com/posts/dragonfly/</guid>
    <description><![CDATA[测试环境 10.0.13.19 部署harbor，单点，docker-compose的方式部署 4核8G 10.0.13.22 dragonfly的supernode节点 16核64G do]]></description>
</item></channel>
</rss>
